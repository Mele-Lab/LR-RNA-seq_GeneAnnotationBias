import pandas as pd

p = os.getcwd()
sys.path.append(p)

# from utils import *

include: 'smkmod/samtools.smk'
include: 'smkmod/formatting.smk'
include: 'smkmod/variant_calling.smk'

configfile: 'snakemake/config.yml'
config_tsv = 'snakemake/array.tsv'
chromosome_tsv = 'snakemake/chromosomes.tsv'
#config_tsv = '/gpfs/projects/bsc83/Projects/pantranscriptome/pclavell/01_basecalling/data/data_array.tsv'

# with open(configfile, 'r') as f:
#     config = yaml.safe_load(f)


df = pd.read_csv(config_tsv, sep='\t')
chromosome_obj = pd.read_csv(chromosome_tsv, sep='\t')


def get_df_val(df, col, sample):
    temp = df.loc[df['sample']==sample]
    assert len(temp.index) == 1
    return temp[col].values[0]

rule all:
    input:
        expand(config['data']['vc']['gatk']['vcf_merged'],
                sample=df['sample'].tolist(),
                chromosome=chromosome_obj['chr'].tolist())

# # TODO map reads to the genome (NOT transcriptome)
# use rule minimap_fq as vc_map_genome with:
#     input:
#         junc_bed = config['ref']['junc_bed'],
#         fq = # TODO fill in fastq,
#         ref_fa = config['ref']['fa_full']
#     output:
#         sam = temporary(config['data']['vc']['map']['sam'])


# TODO MAYBE WE HAVE TO RECOVER THIS RULE BECAUSE I DIDN'T FILTER PFOR PRIMARY MAPPINGS
# # filter reads for primary mappings
# use rule sam_filt_for_primary as vc_filt_mappings with:
#     input:
#         align = rules.vc_map_genome.output.sam
#     output:
#         align = temporary(config['data']['vc']['map']['sam_filt'])

# add rg tag because gatk throws an absolute fit if not
use rule add_rg as vc_add_rg with:
    input:
        align = lambda wc: get_df_val(df, 'fname', wc.sample)
        #align = config['data']['vc']['map']['bam']
    output:
        align = temporary(config['data']['vc']['map']['bam_rg'])

use rule ref_make_gatk_dict as vc_make_dict with:
    input:
        fa = config['ref']['fa_full']
    output:
        fa_dict = config['ref']['fa_dict']

use rule ref_make_fa_ind as vc_fa_ind with:
    input:
        fa = config['ref']['fa_full']
    output:
        fai = config['ref']['fa_full_ind']

# TODO actually write this rule, there's nothing underneath ATM
# split reads based on where introns are because we have spliced data
use rule gatk_split_reads as vc_split_spliced_reads with:
    input:
        fa = rules.vc_make_dict.input.fa,
        align = rules.vc_add_rg.output.align
    output:
        align = temporary(config['data']['vc']['map']['bam_split'])

use rule fix_read_flags as vc_fix_flags with:
    input:
        fa = rules.vc_make_dict.input.fa,
        align = rules.vc_add_rg.output.align,
        split_align = rules.vc_split_spliced_reads.output.align
    output:
        align = temporary(config['data']['vc']['map']['bam_split_flag'])

use rule bam_sort as vc_sort_bam with:
    input:
        align = rules.vc_split_spliced_reads.output.align
    output:
        align = temporary(config['data']['vc']['map']['bam_sort'])

use rule bamindex as vc_ind_bam with:
    input:
        bam = rules.vc_sort_bam.output.align
    output:
        index = config['data']['vc']['map']['bam_sort_ind']

###########################################
########### GATK
###########################################


# actual variant calling
use rule call_variants_gatk as vc_call_variants with:
    input:
        bam = rules.vc_ind_bam.input.bam,
        bai = rules.vc_ind_bam.output.index,
        fa = rules.vc_make_dict.input.fa,
        ind = rules.vc_fa_ind.output.fai,
        dict = rules.vc_make_dict.output.fa_dict
    output:
        vcf = temporary(config['data']['vc']['gatk']['vcf_gz'])

# use rule gunzip as vc_gunzip_vcf with:
#     input:
#         ifile = rules.vc_call_variants.output.vcf
#     output:
#         ofile = config['data']['vc']['gatk']['vcf']

# normalize variants so they're comparable across samples
use rule vcf_norm as vc_vcf_norm with:
    input:
        vcf = rules.vc_call_variants.output.vcf,
        fa = rules.vc_call_variants.input.fa
    output:
        vcf = temporary(config['data']['vc']['gatk']['vcf_norm'])


# NEW PART
def fmt_list_for_cli(x, sep=' '):
    return f'{sep}'.join(x)

#        vcflist = fmt_list_for_cli(list(lambda wildcards: expand(config['data']['vc']['gatk']['vcf_norm'], sample=df['sample'].tolist()))),

# bgzip files so they can be merged
use rule bgzip as compress_vcf with:
    input:
        ifile = rules.vc_vcf_norm.output.vcf
    output:
        gz = temporary(config['data']['vc']['gatk']['vcf_norm_gz'])

# index files so they can be merged
use rule vcfgz_index as index_premerge with:
    input:
        vcfgz = rules.compress_vcf.output.gz
    output:
        index = config['data']['vc']['gatk']['vcf_norm_gz_index']


# merge vcfs of all samples
use rule merge_samples as merging with:
    input:
        mock2 = lambda wildcards: expand(config['data']['vc']['gatk']['vcf_norm_gz_index'], sample=df['sample'].tolist()),
        mock = lambda wildcards: expand(config['data']['vc']['gatk']['vcf_norm_gz'], sample=df['sample'].tolist())
        #reference = config['ref']['fa_full']
    params:
        inputvcfs = (lambda wildcards: fmt_list_for_cli(list(expand(config['data']['vc']['gatk']['vcf_norm_gz'], sample=df['sample'].tolist()))))
    output:
        vcfgz = config['data']['vc']['gatk']['vcf_merged']



# ###################### UNTESTED AREA#########################
# split vcf in chromosomes
use rule vcf_split_into_chr as chr_split with:
    input:
        vcfgz = rules.merging.output.vcfgz
    params:
        chr= lambda wildcards: wildcards.chromosome
    output:
        vcf = config['data']['vc']['filters']['chromosome']

# merge with 1000G chromosomes
use rule merge_samples as merge_with_1000g with:
    input:
        vcf = rules.chr_split.output.vcf
    output:
        vcf = config['data']['vc']['filters']['1000Gchromosome']

# filter positions with some missigness
use rule vcf_filter_missing_pos as filter_incomplete with:
    input:
        vcf =  rules.merge_with_1000g.output.vcf
    output:
        vcf = config['data']['vc']['filters']['vcf_merged_complete']



# # prune merged vcf

# use rule vcf_pruning as prune with:
#     input:
#         vcf = rules.merging.output.vcfgz,
#         psam = config['data']['vc']['gatk']['vcf_merged_psam']
#     params:
#         output_prefix = config['params']['outputprefix']
#     output:
#         mock = config['data']['vc']['gatk']['mock1']

# # pca

# use rule vcf_pca as pca with:
#     input:
#         vcf = rules.merging.output.vcfgz,
#         mock = rules.prune.output.mock
#     params:
#         input_prefix = config['params']['outputprefix'],
#         output_prefix = config['params']['outputprefix2']
#     output:
#         mock = config['data']['vc']['gatk']['mock2']

# TODO UNQUOTE# use rule vcf_pca_no_pruning as pca with:
#     input:
#         vcf = rules.filter_incomplete.output.vcf
#     params:
#         input_prefix = config['params']['outputprefix'],
#         output_prefix = config['params']['outputprefix2']
#     output:
#         mock = config['data']['vc']['gatk']['mock2']