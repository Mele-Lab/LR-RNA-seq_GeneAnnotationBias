import pandas as pd

p = os.getcwd()
sys.path.append(p)

from utils import *

include: 'blast.smk'
include: 'samtools.smk'
include: 'formatting.smk'
include: 'minimap.smk'

configfile: 'config.yml'
# df = pd.read_csv('test_data.tsv', sep='\t')
df = pd.read_csv('test_data_2.tsv', sep='\t')

def get_df_val(df, col, sample):
    temp = df.loc[df['sample']==sample]
    assert len(temp.index) == 1
    return temp[col].values[0]

rule all:
    input:
        expand(config['data']['qc']['bam'],
               sample=df['sample'].tolist())
        # expand(config['data']['duplex']['sam'],
        #        sample=df['sample'].tolist())


# get duplex status of each read and record in new bam
# corresponds to scripts/00.1_append_samtag.sh
use rule add_duplex_status as basecall_add_duplex_status with:
    input:
        align = lambda wc: get_df_val(df, 'fname', wc.sample)
        # fq = config['raw']['fq']
    params:
        sep = config['params']['duplex_sep']
    output:
        align = temporary(config['data']['duplex']['sam'])

# get the read IDs of all reads
use rule sam_get_read_ids as get_all_read_ids with:
    input:
        align = rules.basecall_add_duplex_status.output.align
    output:
        txt = config['data']['duplex']['read_ids']

use rule sam_to_fq as duplex_sam_to_fq with:
    input:
        align = rules.basecall_add_duplex_status.output.align
    output:
        fq = temporary(config['data']['duplex']['fq'])

# corr. to 00_fastq2fasta.sh
use rule fq_to_fa as raw_fq_to_fa with:
    input:
        fq = rules.duplex_sam_to_fq.output.fq
        # fq = lambda wc: get_df_val(df, 'fname', wc.sample)
        # fq = config['raw']['fq']
    output:
        fa = config['data']['duplex']['fa']

# corr. to 01_blast/00_create_db.sh
use rule make_blast_db as blast_db with:
    input:
        fa = config['ref']['linker_5_fa']
    params:
        db = config['data']['blast']['db']
    output:
        nhr = config['data']['blast']['nhr'],
        nin = config['data']['blast']['nin'],
        nsq = config['data']['blast']['nsq']

# corr to 01_blast/01_blast.sh
use rule blast as blast_seq with:
    input:
        fa = rules.raw_fq_to_fa.output.fa,
        nhr = rules.blast_db.output.nhr
    params:
        db = rules.blast_db.params.db
    output:
        xml = config['data']['blast']['xml']

# corr to 01_blast/02_xml2sam
use rule blast2bam as blast2bam_seq with:
    input:
        ref_fa = config['ref']['fa'],
        fa = rules.blast_seq.input.fa,
        xml = rules.blast_seq.output.xml
    params:
        blast2bam = config['bin']['blast2bam']
    output:
        sam = temporary(config['data']['blast']['sam'])

# filter out unmapped reads
use rule sam_filt_unmapped as filt_sam_blast with:
    input:
        align = rules.blast2bam_seq.output.sam
    output:
        align = config['data']['blast']['sam_filt']
        # align = temporary(config['data']['blast']['sam_filt'])

# filter out supplementary and secondary reads (ie only primary)
use rule sam_filt_for_primary as filt_sam_blast_2 with:
    input:
        align = rules.filt_sam_blast.output.align
    output:
        align = config['data']['blast']['sam_filt_2']

use rule sam_to_bam as sam_to_bam_blast with:
    input:
        align = rules.filt_sam_blast_2.output.align
    output:
        align = temporary(config['data']['blast']['bam'])

use rule sam_sort as bam_sort_blast with:
    input:
        align = rules.sam_to_bam_blast.output.align
    output:
        align = config['data']['blast']['bam_sort']

use rule bam_index as bam_index_blast with:
    input:
        align = rules.bam_sort_blast.output.align
    output:
        align = config['data']['blast']['bam_ind']

# corr. to 02_extract_UMI/01_extract_UMI.sh
use rule extract_umi as extract_umi_blast with:
    input:
        align = rules.filt_sam_blast.output.align
    params:
        opref = config['data']['umi']['umis'].split('_extracted_UMI.tsv')[0],
        sep = config['params']['umi_sep']
    output:
        umis = config['data']['umi']['umis'],
        fa = config['data']['umi']['fa']

use rule fasta_get_read_ids as get_umi_read_ids with:
    input:
        fa = rules.extract_umi_blast.output.fa
    output:
        txt = config['data']['umi']['read_ids']

# get the read ids of reads that we didn't find UMIs for
# by subtracting the reads with a UMI from the list of all reads
use rule read_id_diff as get_non_umi_read_ids with:
    input:
        a = rules.get_all_read_ids.output.txt,
        b = rules.get_umi_read_ids.output.txt
    output:
        txt = config['data']['umi']['no_umi_read_ids']

# TODO this is where the duplex read recovery will happen

# corr. to 03_genome_mapping/01_minimap.sh
use rule minimap as map with:
    input:
        junc_bed = config['ref']['junc_bed'],
        fa = rules.extract_umi_blast.output.fa,
        ref_fa = config['ref']['fa']
    output:
        sam = config['data']['minimap']['sam']
        # sam = temporary(config['data']['minimap']['sam'])

# rules below corr. to 03_genome_mapping/02_filter_and_transform_results
use rule align_filt_unmapped_supp as filt_sam_map with:
    input:
        align = rules.map.output.sam
    output:
        align = config['data']['minimap']['sam_filt']

use rule sam_to_bam as sam_to_bam_map with:
    input:
        align = rules.filt_sam_map.output.align
    output:
        align = temporary(config['data']['minimap']['bam'])

use rule sam_sort as bam_sort_map with:
    input:
        align = rules.sam_to_bam_map.output.align
    output:
        align = config['data']['minimap']['bam_sort']

use rule bam_index as bam_index_map with:
    input:
        align = rules.bam_sort_map.output.align
    output:
        align = config['data']['minimap']['bam_ind']

# rules below correspond to 05_deduplication/01_deduplication.sh
use rule gtf_to_gt_map as get_gt_map with:
    input:
        gtf = config['ref']['gtf']
    output:
        gt_map = config['ref']['gt_map']

use rule dedupe_umi as umi_dedupe_reads with:
    input:
        align = rules.bam_sort_map.output.align,
        gt_map = config['ref']['gt_map']
    params:
        sep = config['params']['umi_sep'],
        edit_dist = 2
    output:
        align = config['data']['umi_dedupe']['bam'],
        log = config['data']['umi_dedupe']['log']

# get read IDs of reads that we UMI deduplicate
use rule sam_get_read_ids as get_umi_dedupe_read_ids with:
    input:
        align = rules.umi_dedupe_reads.output.align
    output:
        txt = config['data']['umi_dedupe']['read_ids']

# get bam file of
# 1. UMI deduplicated reads
# 2. reads that we didn't find UMIs for
use read_id_union as get_qc_reads with:
    input:
        a = rules.get_non_umi_read_ids.output.txt,
        b = rules.get_umi_dedupe_read_ids.output.txt
    output:
        txt = config['data']['qc']['read_ids']

use rule sam_filt_for_read_ids as make_qc_bam with:
    input:
        align = rules.get_all_read_ids.input.align,
        read_ids = rules.get_qc_reads.output.txt
    output:
        align = config['data']['qc']['bam']
